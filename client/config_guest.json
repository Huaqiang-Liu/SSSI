{
  "role": "guest",
  "model_name": "llama3-1b",
  "partition_model_dir" : "model/llama3-partitioned/",
  "max_tokens": 64,
  "deprecated_layers_to_inference": [[0,1], [14,15,16]],
  "layers_to_inference": [[0,1,2,3]],
  "shm_path": "/sys/bus/pci/devices/0000:00:02.0/resource2",
  "temperature": 0.0
}